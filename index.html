<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Shu-Wei Lu - Research</title>
  <style>
    body {
      font-family: 'Helvetica Neue', sans-serif;
      margin: 0;
      padding: 0 1rem;
      max-width: 800px;
      margin: auto;
      line-height: 1.6;
      color: #333;
    }
    h1, h2, h3 {
      color: #111;
    }
    nav {
      margin-top: 2rem;
      margin-bottom: 2rem;
    }
    nav a {
      margin-right: 15px;
      text-decoration: none;
      color: #007acc;
    }
    section {
      margin-bottom: 3rem;
    }
    .pub-title {
      font-weight: bold;
    }
    .pub-authors {
      font-style: italic;
    }
    a{
    color: #007acc;
    text-decoration: none;
    border-bottom: 1px solid transparent;
    transition: all 0.2s ease;
    }
    a:hover {
    border-bottom: 1px solid #007acc;
    }
    #publications a.pub-link {
      background-color: #f0f0f0;
      padding: 2px 6px;
      border-radius: 4px;
      color: #070707;
      text-decoration: none;
      font-size: 0.9rem;
      transition: background 0.2s ease;
    }
    #publications a.pub-link:hover {
      background-color: #ddd;
    }
  </style>
</head>
<body>

  <h1>Shu-Wei Lu</h1>
  <p><strong>Research Scientist | Computer Vision </strong></p>
  <p><a href="mailto:shuweilu@nycu.edu.tw">shuweilu@nycu.edu.tw</a> |
    <a href="https://scholar.google.com/citations?user=QWXJB6sAAAAJ&hl=zh-TW">Google Scholar</a> | 
    <a href="https://github.com/nargoo0328">GitHub</a></p>

  <!-- <nav>
    <a href="#about">About</a>
    <a href="#education">Education</a>
    <a href="#research">Research</a>
    <a href="#publications">Publications</a>
  </nav> -->

  <section id="about">
    <h2>About Me</h2>
    <p>
      I’m a research scientist working on 3D perception and scene reconstruction for autonomous systems. 
      I’m interested in bridging the gap between visual understanding and downstream planning via 3D representations, simulation, and neural rendering.
    </p>
  </section>

  <section id="education">
    <h2>Education</h2>
    <ul>
      <li><strong>National Yang Ming Chiao Tung University</strong>, 2018–2022<br />
        B.S. in Mathematics and Computer Science
      </li>
    </ul>
  </section>

  <!-- <section id="research">
    <h2>Research Interests</h2>
    <ul>
      <li>Bird’s Eye View Semantic Segmentation</li>
      <li>Uncertainty Modeling in Depth Estimation</li>
      <li>Gaussian Splatting for Scene Reconstruction</li>
      <li>Neural Rendering for Simulation</li>
    </ul>
  </section> -->

  <section id="publications">
    <h2>Publications</h2>
  
    <div class="publication">
      <img src="images/PF_BCP.gif" alt="Visual-ROI" style="width:100%; max-width:400px; margin-bottom:10px;" />
      <p class="pub-title">Potential Field as Scene Affordance for Behavior Change-Based Visual Risk Object Identification</p>
      <p class="pub-authors">
        Pang-Yuan Pao, 
        <strong>Shu-Wei Lu</strong>, 
        Ze-Yan Lu, 
        Yi-Ting Chen
      </p>
      <p><em>ICRA, 2025</em></p>
      <p>We study behavior change-based visual risk object identification (Visual-ROI), a critical framework designed to detect potential hazards for intelligent driving systems.</p>
      <p class="pub-links">
        <a class="pub-link" href="https://hcis-lab.github.io/PF-BCP/">project page</a> / 
        <a class="pub-link" href="https://arxiv.org/abs/2409.15846">paper</a> / 
        <a class="pub-link" href="https://github.com/HCIS-Lab/PF-BCP">code</a>
      </p>
    </div>
  
    <div class="publication">
      <img src="images/action-slot.gif" alt="Action-slot" style="width:100%; max-width:400px; margin-bottom:10px;" />
      <p class="pub-title">Action-slot: Visual Action-centric Representations for Atomic Activity Recognition in Traffic Scenes</p>
      <p class="pub-authors">
        Chi-Hsi Kung, 
        <strong>Shu-Wei Lu</strong>, 
        Yi-Hsuan Tsai, 
        Yi-Ting Chen
      </p>
      <p><em>CVPR, 2024</em></p>
      <p>We use Action-slot to represent atomic activities. The learned attention can discover and localize atomic activities with only weak video labels and without using any perception module (e.g., object detector).</p>
      <p class="pub-links">
        <a class="pub-link" href="https://hcis-lab.github.io/Action-slot/">project page</a> / 
        <a class="pub-link" href="https://openaccess.thecvf.com/content/CVPR2024/html/Kung_Action-slot_Visual_Action-centric_Representations_for_Multi-label_Atomic_Activity_Recognition_in_CVPR_2024_paper.html">CVF</a> / 
        <a class="pub-link" href="https://arxiv.org/abs/2311.17948">arXiv</a> / 
        <a class="pub-link" href="https://github.com/HCIS-Lab/Action-slot/tree/main">code</a> / 
        <a class="pub-link" href="https://nycu1-my.sharepoint.com/:f:/g/personal/ychen_m365_nycu_edu_tw/EnRg1zT7CeZGg3Ju2TIP1j8B0NB0fCpYsjGQBc0Tcf2H6w?e=FGJvTc">TACO dataset</a>
      </p>
    </div>
  
    <div class="publication">
      <img src="images/riskbench.gif" alt="RiskBench" style="width:100%; max-width:400px; margin-bottom:10px;" />
      <p class="pub-title">RiskBench: A Scenario-based Benchmark for Risk Identification</p>
      <p class="pub-authors">
        Chi-Hsi Kung, 
        Chieh-Chi Yang, 
        Pang-Yuan Pao, 
        <strong>Shu-Wei Lu</strong>, 
        Pin-Lun Chen, 
        Hsin-Cheng Lu, 
        Yi-Ting Chen
      </p>
      <p><em>ICRA, 2024</em></p>
      <p>The FIRST benchmark that enables evaluation of various types of risk identification algorithms, including rule-based, trajectory-prediction-based, collision prediction, and behavior-change-based methods. We also assess the influence of risk identification on downstream driving tasks.</p>
      <p class="pub-links">
        <a class="pub-link" href="https://hcis-lab.github.io/RiskBench/">project page</a> / 
        <a class="pub-link" href="https://arxiv.org/abs/2312.01659">paper</a> / 
        <a class="pub-link" href="https://github.com/HCIS-Lab/RiskBench">code</a> / 
        <a class="pub-link" href="https://nycu1-my.sharepoint.com/personal/ychen_m365_nycu_edu_tw/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fychen%5Fm365%5Fnycu%5Fedu%5Ftw%2FDocuments%2FRiskBench&ga=1">dataset</a> 
      </p>
    </div>
  </section>  

  <!-- <section id="talks">
    <h2>Talks & Presentations</h2>
    <ul>
      <li><em>(To be added)</em></li>
    </ul>
  </section> -->

  <!-- <footer>
    <p style="font-size: 0.9rem; color: #777;">Last updated: March 2025</p>
  </footer> -->

</body>
</html>
